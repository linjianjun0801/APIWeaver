# LangChain + OpenAI 集成（调用 APIWeaver 工具）使用说明

本文档说明如何把 LangChain（使用 OpenAI 作为 LLM）与 APIWeaver MCP 管理工具整合，让 LLM 能以“工具调用（tools）”的方式操作和调用外部 Web APIs（通过 APIWeaver 管理）。

目录
- 先决条件
- 启动 APIWeaver MCP server
- 启动 Admin HTTP 管理服务（apis.json 持久化）
- 安装依赖
- 运行 LangChain Agent 示例
- 如何扩展和在生产中使用
- 常见问题与调试

---

## 先决条件
- Python 3.10+
- 已安装并能运行 APIWeaver（仓库代码）
- OpenAI API key（环境变量 OPENAI_API_KEY）
- 推荐在虚拟环境中操作

---

## 启动 APIWeaver MCP server
这是你已有的 MCP 服务：可按 README 启动（示例使用 streamable-http transport）：
```bash
# 默认（stdio）
apiweaver run

# 推荐（Streamable HTTP）
apiweaver run --transport streamable-http --host 127.0.0.1 --port 8000
```
注意：MCP server 负责将每个已注册 API 的 endpoint 作为 MCP 工具暴露给 MCP 客户端（例如 AI 助手）。我们的 admin HTTP 服务会直接在同一进程创建/管理 APIWeaver 实例（见下面）。

---

## 启动 Admin HTTP 管理服务
我提供了一个 FastAPI-based 管理服务（apiweaver/admin_http.py），默认监听 127.0.0.1:9000（可以用 uvicorn 启动）。
- 功能：
  - 持久化所有已注册 API 到 `apis.json`（支持多 server）
  - 提供 REST 管理接口：注册/移除/列出/测试/获取 schema
  - 启动时自动从 `apis.json` 加载并在内存中注册（创建 MCP 工具）

启动：
```bash
pip install fastapi uvicorn httpx
uvicorn apiweaver.admin_http:app --host 127.0.0.1 --port 9000
```

常用路由：
- POST /admin/{server}/register  body: {"config": {...APIConfig...}}
- POST /admin/{server}/unregister body: {"api_name":"..."}
- GET  /admin/{server}/list
- POST /admin/{server}/test       body: {"api_name":"..."}
- GET  /admin/{server}/schema/{api_name}?endpoint=...

安全注意：示例没有鉴权，请勿在未保护的网络上直接暴露。生产环境请加 auth（Bearer token/Basic/mTLS）并确保使用 HTTPS。

---

## 安装 LangChain 示例依赖
示例脚本使用 LangChain + OpenAI + httpx。安装依赖：
```bash
pip install langchain openai httpx
```
（根据你使用的 langchain 版本，包名或 API 可能略有不同）

设置 OpenAI API Key：
```bash
export OPENAI_API_KEY="sk-..."
# Windows (PowerShell)
# setx OPENAI_API_KEY "sk-..."
```

配置 admin URL（可选，默认 http://127.0.0.1:9000）：
```bash
export APIWEAVER_ADMIN_URL="http://127.0.0.1:9000"
```

---

## 运行 LangChain Agent 示例
示例文件： `examples/langchain_agent.py`

运行：
```bash
python examples/langchain_agent.py
```

脚本会演示：
1. 使用 register_api 工具注册一个示例 API（OpenWeatherMap 示例）
2. 使用 list_apis 查看已注册 API
3. 调用 call_api 示例（注意：需要 admin HTTP 支持 call 路由，或你可扩展 admin_http.py 添加 /admin/{server}/call 去调用 weaver._execute_api_call）

如果你需要直接用 LangChain 调用已注册的 MCP 工具（不走 admin HTTP），可实现一个 MCP 客户端工具（或通过 fastmcp 客户端库）将 MCP 工具暴露给 LangChain，但那需要实现 MCP 协议的客户端库或使用已有 MCP 客户端。

---

## 如何扩展 / 进阶
- 在 admin_http.py 中添加 /admin/{server}/call 路由：该路由直接调用 weaver._execute_api_call(api_name, endpoint_name, params) 并返回结果（安全注意：需限制可调用的 API 和参数）。
- 在 LangChain 工具中实现更高层语义解析器：让 LLM 只输入自然语言，工具负责把自然语言解析成 JSON payload（并做验证）。
- 持久化：当前实现使用单文件 apis.json；在多进程/多副本部署时请用数据库（SQLite/Postgres）或 key-value（Redis）并实现分布式锁。
- 认证：启用 JWT/API Key/Basic Auth 来保护 admin HTTP 路由。

---

## 常见问题与调试
- 注册失败（400/500）：检查传入的 config 是否符合 APIWeaver 的 APIConfig 模型（字段名、参数格式）。
- 连接失败（test_api_connection 报错）：检查 base_url、网络联通性、认证字段（api_key / bearer token）。
- 多实例部署冲突：多个进程写入同一个 apis.json 会产生竞争，使用 DB 或每 server 一个文件并配文件锁。

---

## 总结
- 我为你实现了一个 LangChain 示例 agent（使用 OpenAI LLM）并把管理/调用 API 的动作通过 admin HTTP 路由封装为工具（tools）。  
- 你可以把该 agent 集成到更大的自动化流程里：LLM 通过 tools 做出决策并执行 API 操作（注册、调用、检测、移除、读取 schema）。  
- 请务必在生产环境增强安全（认证与加密）与持久化/并发处理（DB/文件锁）。
